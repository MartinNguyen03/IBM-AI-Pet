{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv1D, Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from efficientnet_lite import EfficientNetLiteB0\n",
    "from IPython.display import clear_output\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_30 (Conv1D)          (None, 15001, 1)          1001      \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 15001, 1)          0         \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, 14002, 1)          1001      \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 14002, 1)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 14002)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 28006     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,008\n",
      "Trainable params: 30,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer([16000, 1]))\n",
    "model.add(Conv1D(1, 1000, 1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(1, 1000, 1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=3, restore_best_weights=True)\n",
    "model.compile(optimizer=Adam(lr=1e-4),loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import wavio as wv\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100\n",
    "duration = 2 # Waiting time in seconds\n",
    "recording = sd.rec(int(duration * fs), samplerate=fs, channels=2)\n",
    "\n",
    "sd.wait() # Wait for the recording to finish\n",
    "\n",
    "dir = r\"C:\\Users\\Jerry\\OneDrive\\Documents\\Imperial\\3rd year\\3rd year Group project\\Train data\\Voices\\owner 1\" # Directory folder to store user voice data\n",
    "write(dir + \"\\0.wav\", fs, recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 16000 # number of data points to read at a time\n",
    "fs = 44100\n",
    "\n",
    "p = pyaudio.PyAudio() # start the PyAudio class\n",
    "stream=p.open(format=pyaudio.paInt16,channels=1, rate = fs, input=True, frames_per_buffer = window_size) #uses default input device\n",
    "\n",
    "while True:\n",
    "    data = np.fromstring(stream.read(window_size) ,dtype = np.int16)[:, None]\n",
    "    score_raw = model.predict(data[None])[0]\n",
    "    score = tf.math.argmax(score_raw)\n",
    "    print(score)\n",
    "    \n",
    "    if score == 1:\n",
    "        print('Hi boss!')\n",
    "    elif score == 0:\n",
    "        print('Anyone there?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dir = r'C:\\Users\\Jerry\\OneDrive\\Documents\\Imperial\\3rd year\\3rd year Group project\\Train data\\Voices' # Directory folder which stores all the voice data\n",
    "data = tf.keras.utils.audio_dataset_from_directory(dir, output_sequence_length = 16000, label_mode = 'categorical', batch_size = 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 16000, 1)\n"
     ]
    }
   ],
   "source": [
    "for audios, labels in data.take(1):  # Takes the 1st batch; in our case there's only 1 batch\n",
    "    train_X = audios.numpy()\n",
    "    labels = labels.numpy()\n",
    "train_X = tf.math.reduce_sum(train_X, axis = -1)[..., None]\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.4839\n",
      "Epoch 2/3\n",
      "62/62 [==============================] - 7s 113ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.4839\n",
      "Epoch 3/3\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.4839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e78f4f4f50>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, labels, epochs=3, batch_size = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
